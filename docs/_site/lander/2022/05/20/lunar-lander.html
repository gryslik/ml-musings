<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="/assets/css/style.css?v=" media="screen" type="text/css">
    <link rel="stylesheet" href="/assets/css/print.css" media="print" type="text/css">

    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Lunar Lander - Introduction | ML Musings</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Lunar Lander - Introduction" />
<meta name="author" content="Daniel Mogilevsky" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Introduction In reinforcement learning, an agent (an entity that makes decisions) gets rewarded or punished for its actions, and over time optimizes itself to better perform as it learns what actions yield the highest reward." />
<meta property="og:description" content="Introduction In reinforcement learning, an agent (an entity that makes decisions) gets rewarded or punished for its actions, and over time optimizes itself to better perform as it learns what actions yield the highest reward." />
<link rel="canonical" href="http://localhost:4000/lander/2022/05/20/lunar-lander.html" />
<meta property="og:url" content="http://localhost:4000/lander/2022/05/20/lunar-lander.html" />
<meta property="og:site_name" content="ML Musings" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-05-20T14:16:40-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Lunar Lander - Introduction" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Daniel Mogilevsky"},"dateModified":"2022-05-20T14:16:40-04:00","datePublished":"2022-05-20T14:16:40-04:00","description":"Introduction In reinforcement learning, an agent (an entity that makes decisions) gets rewarded or punished for its actions, and over time optimizes itself to better perform as it learns what actions yield the highest reward.","headline":"Lunar Lander - Introduction","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/lander/2022/05/20/lunar-lander.html"},"url":"http://localhost:4000/lander/2022/05/20/lunar-lander.html"}</script>
<!-- End Jekyll SEO tag -->


    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>

  <body>
    <header>
      <div class="inner">
        <a href="http://localhost:4000/">
          <h1>ML Musings</h1>
        </a>
        <h2>An exploration of machine learning</h2>
        
        
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h3>Introduction</h3>
<p>In reinforcement learning, an agent (an entity that makes decisions) gets rewarded or 
punished for its actions, and over time optimizes itself to better perform as it learns what actions yield the highest reward.</p>

<p>In this series, we use reinforcement learning to make an intelligent lunar lander playing AI.</p>

<p>The rules of Lunar Lander are simple. The user controls a lander by firing a combination of three thrusters:
down, left, and right. The player must fire these thrusters in a way to safely land within the area marked by the flags.</p>

<p><img src="/images/lunar_lander.png" alt="Lunar Lander Game Guide" /></p>

<h3>Environment</h3>
<p>To play this game with an AI, we will be using the <a href="https://www.gymlibrary.ml/environments/box2d/lunar_lander/">Gym Box2D lunar lander environment</a>. 
This environment takes care of many things for us, such as creating the actual game, its rules, and providing a way
for our AI to play the game. The environment specifies the following rewards and punishments:</p>

<p>Rewards:</p>
<ul>
  <li>Moving from the top of the screen to the landing pad yields 100-140 points, which are lost if the lander moves away from the landing zone</li>
  <li>Each leg that contacts the ground yields 10 points</li>
  <li>If the lander comes to rest, it gets 100 points</li>
</ul>

<p>Punishments:</p>
<ul>
  <li>Firing the down thruster is -0.3 points per frame</li>
  <li>Firing either of the side thrusters is -0.03 points per frame</li>
  <li>Crashing the lander is -100 points</li>
</ul>

<p>Each iteration of the game is an “episode”, and an episode ends when the lander comes to rest, crashes, leaves the screen, or achieves a certain score (200).
If the agent ends the episode with a score of 200 or more, the game has been won.</p>

<p>An episode is split into “frames”, a frame being the smallest time slice in a game (FPS in a video game). Our agent
makes calculations every frame. You’ll see this referenced often.</p>

<p>For more information, visit the Lunar Lander environment link above.</p>

<p>Now that we understand our constraints, let’s get our solution setup and working.</p>

<h3>Setting up the project</h3>

<p>Before installing everything we need, you can do the optional step of installing <a href="https://www.anaconda.com/">Anaconda</a>
and <a href="https://www.machinelearningplus.com/deployment/conda-create-environment-and-everything-you-need-to-know-to-manage-conda-virtual-environment/">creating a conda environment</a>. 
This is recommended, but completely unnecessary, so feel free to skip this step if you are fine with installing python
packages outside of a virtual environment.</p>

<p>Now, the following must be installed for our project to run:</p>
<ul>
  <li><a href="https://www.python.org/downloads/">Python 3</a></li>
  <li><a href="https://numpy.org/install/">Numpy</a></li>
  <li><a href="https://www.tensorflow.org/install/">Tensorflow</a></li>
  <li><a href="https://pypi.org/project/gym/">Gym</a></li>
  <li><a href="https://pypi.org/project/pandas/">Pandas</a></li>
  <li><a href="https://git-scm.com/downloads">Git</a> (Optional, makes it easy to clone the Git repository with all our code)</li>
</ul>

<p>Once you have the above, clone the <a href="https://github.com/gryslik/ml-musings/tree/lunar_lander">Lunar Lander Git repo</a> by
running the following in a terminal</p>

<p><code>git clone git@github.com:gryslik/ml-musings.git</code></p>

<h3>Running the trainer</h3>
<p>To run the project, go into the project directory and from the terminal run:</p>
<p><code>python3 main.py</code></p>

<p>When prompted, enter “1” to start training the agent. This will take a while. Your output should
look like the below and continue for a while</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>======================================================
Processing episode: 0
======================================================
1/1 [==============================] - 1s 857ms/step
1/1 [==============================] - 0s 60ms/step
1/1 [==============================] - 0s 40ms/step
1/1 [==============================] - 0s 52ms/step
1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - 0s 18ms/step
2022-06-29 18:58:58.907627: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled
2022-06-29 18:58:58.950908: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 11ms/step
1/1 [==============================] - 0s 18ms/step
2022-06-29 18:58:59.378810: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled
1/1 [==============================] - 0s 14ms/step
1/1 [==============================] - 0s 12ms/step
1/1 [==============================] - 0s 16ms/step
--------------------------------------------------------
Episode: 0 completed in: 78 steps.
--------------------------------------------------------
Failed to complete episode: 0 with a total reward of: -137.2459988101599
Processing episode: 0 took: 3 seconds. Avg running reward is: -137.2459988101599
======================================================
Processing episode: 1
======================================================
</code></pre></div></div>

<h3>While the agent is training, check
out the next blog post which talks about the project structure and what's happening as you're waiting.</h3>


        </section>

        <aside id="sidebar">
          

          

          <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</p>
        </aside>
      </div>
    </div>

  </body>
</html>